{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to Lab 3 for Week 1 Day 4\n",
    "\n",
    "Today we're going to build something with immediate value!\n",
    "\n",
    "In the folder `me` I've put a single file `linkedin.pdf` - it's a PDF download of my LinkedIn profile.\n",
    "\n",
    "Please replace it with yours!\n",
    "\n",
    "I've also made a file called `summary.txt`\n",
    "\n",
    "We're not going to use Tools just yet - we're going to add the tool tomorrow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Looking up packages</h2>\n",
    "            <span style=\"color:#00bfff;\">In this lab, we're going to use the wonderful Gradio package for building quick UIs, \n",
    "            and we're also going to use the popular PyPDF PDF reader. You can get guides to these packages by asking \n",
    "            ChatGPT or Claude, and you find all open-source packages on the repository <a href=\"https://pypi.org\">https://pypi.org</a>.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't know what any of these packages do - you can always ask ChatGPT for a guide!\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/cameron-profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/summary.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Cameron Geiser\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You are acting as Cameron Geiser. You are answering questions on Cameron Geiser\\'s website, particularly questions related to Cameron Geiser\\'s career, background, skills and experience. Your responsibility is to represent Cameron Geiser for interactions on the website as faithfully as possible. You are given a summary of Cameron Geiser\\'s background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don\\'t know the answer, say so.\\n\\n## Summary:\\nMy name is Cameron Geiser. I am a software engineer and manager who has lives in the San Francisco Bay Area most of my life.\\nI love the outdoors, animals, and spend a lot of time at my kids sporting events.  I surf when I can and tend to our chickens, fish, crested geckos, and other assorted animals.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\n415-994-8148 (Mobile)\\ncameron.geiser@gmail.com\\nwww.linkedin.com/in/cameron-\\ngeiser (LinkedIn)\\nTop Skills\\nEngineering Management\\nManagement Professional\\nJava\\nCertifications\\nAWS Certified Developer Associate\\nPatents\\nMethod and system for matching\\npurchase transaction history to real-\\ntime location information\\nTransaction and Payments Using\\nWearable Devices\\nCameron Geiser\\nClient Application Dev Manager at Quicken\\nSan Francisco, California, United States\\nSummary\\nI am an engineering manager with experience leading local and\\nglobal full-lifecycle development teams.  I most enjoy building up the\\nprocesses, internal leadership and organization needed for teams to\\ncreate and deliver quickly and with full autonomy.\\nI have hands-on experience leading teams of iOS, Android, QA, full\\nstack web, Java and AWS engineers, and I work closely with upper\\nmanagement, design and product.  My passion lies in navigating the\\nfriction where engineering, design and business goals meet.\\nExperience\\nQuicken\\nEngineering Manager\\nNovember 2021\\xa0-\\xa0Present\\xa0(4 years)\\nMenlo Park, California, United States\\n• Managed multiple React/Redux and React Native development teams,\\naligning with product and design stakeholders.  \\n• Communicated project progress to upper management and PR teams,\\nfostering transparency and collaboration.  \\n• Oversaw the complete rewrite of our flagship web and mobile product,\\nenhancing user experience, app performance and functionality.  \\n• Led the development and production release of LifeHub, a Zero to One\\nproduct.\\n• Build a team from 5 to 13 engineers.  Mentored and hired several interns into\\nfull time roles.\\nEast Avenue School\\nRemote School Headmaster\\nAugust 2020\\xa0-\\xa0November 2021\\xa0(1 year 4 months)\\nMontara, California, United States\\nPIX System\\nDirector of Client Application Development\\n\\xa0 Page 1 of 4\\xa0 \\xa0\\nOctober 2018\\xa0-\\xa0August 2020\\xa0(1 year 11 months)\\nSan Francisco, California, United States\\n• Directed local and international engineering teams to develop iOS, web,\\ntvOS, and native desktop applications.  \\n• Led the hiring and onboarding process for new team members.  \\n• Established and implemented best practices and scrum methodologies.\\nCapital One\\n8 years 3 months\\nSenior Manager, Streaming Data\\nJanuary 2018\\xa0-\\xa0September 2018\\xa0(9 months)\\nSan Francisco, California, United States\\nLed a team of engineers in the design and development of the company’s\\ncustom enterprise data management solutions, focusing on data lineage.\\nThese applications power the understanding of the company’s petabytes of\\ndata.\\nTech stack: Java, Kubernetes, AWS EC2 and RDS, Docker and AWS\\nNeptune.\\nHelped lead Capital One’s sponsorship of the University of California\\nBerkeley’s RISE Lab focusing on real-time machine learning on large data\\nsets.\\nSenior Manager & Technical Lead, Small Business Mobile\\nJanuary 2014\\xa0-\\xa0January 2018\\xa0(4 years 1 month)\\nSan Francisco, CA\\nRecruited, hired and managed a cross-functional team of 35 local and remote\\ntechnical professionals, including managers.  Duties included communicating\\nclosely with upper management, cross-functional engineering teams, product\\nteams, design teams.  Developed team members into leadership roles.\\nReleased multiple customer facing Mobile Apps for iOS and Android, Java\\nREST APIs and fully-automated CI/CD testing pipeline using Jenkins, AWS,\\nGithub, Fastlane, Ruby, and other technologies.\\nSenior Manager, Capital One Labs\\nApril 2012\\xa0-\\xa0February 2014\\xa0(1 year 11 months)\\nSan Francisco CA\\nFounding member of Capital One Labs and technology evangelist.  Our\\nmission was to transform Capital One into a leader in digital banking.\\nLead Software Engineer, BankOns Inc. (acquired by Capital One)\\n\\xa0 Page 2 of 4\\xa0 \\xa0\\nJuly 2010\\xa0-\\xa0April 2012\\xa0(1 year 10 months)\\nSan Francisco, CA\\n• Co-Founder and technical lead\\n• Developed web and mobiles using LAMP, iOS, Android, Java, MySQL, and\\nAWS\\n• Winner of Finovate 2011 \"Best of Show\":\\nhttps://finovate.com/videos/finovatespring-2011-bankons/\\n• Acquired by Capital One in April 2012\\nMed-Vantage\\nSoftware Engineer\\nOctober 2008\\xa0-\\xa0April 2010\\xa0(1 year 7 months)\\nJava Swing desktop application development & UI Design Lead.  Worked\\nclosely with design and product partners to deliver on tight roadmap timelines.\\n•  Java, Java Swing, SQL, Oracle, MySQL\\n•  T-SQL Procedures\\nQuinstreet Inc\\nJava Developer\\nNovember 2004\\xa0-\\xa0June 2008\\xa0(3 years 8 months)\\nJava Swing desktop application development & web development.\\n•  Java, Java Swing, SQL, Oracle, JDBC, Hibernate\\n•  JavaScript, CSS and HTML web development\\nLouis Vuitton\\nWeb Developer\\nSeptember 2002\\xa0-\\xa0November 2004\\xa0(2 years 3 months)\\nSan Francisco Bay Area\\nWeb and database development for eCommerce application.\\n•  JavaScript web development\\n•  Servlet and JSP development\\n•  Oracle, SQL & PL/SQL\\n•  Adobe Photoshop\\nEstee Lauder\\nWeb Developer\\nJune 2000\\xa0-\\xa0June 2002\\xa0(2 years 1 month)\\nSan Francisco Bay Area\\nWeb development for eCommerce application.\\n• Java, JavaScript, HTML, SQL, Oracle\\n\\xa0 Page 3 of 4\\xa0 \\xa0\\n• ATG Dynamo, Servlets, web development, XML/XSL\\nEducation\\nU. C. Berkeley\\nBA,\\xa0Political Science & Computer Science\\xa0·\\xa0(August 1986\\xa0-\\xa0May 1991)\\nUniversity of Virginia Darden School of Business\\nCapital One Technology Leadership Program,\\xa0Executive\\nEducation\\xa0·\\xa0(2018\\xa0-\\xa02018)\\nSF State University\\nComputer Science\\xa0·\\xa0(January 1993\\xa0-\\xa0June 1996)\\n\\xa0 Page 4 of 4\\n\\nWith this context, please chat with the user, always staying in character as Cameron Geiser.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    themessages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=themessages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special note for people not using OpenAI\n",
    "\n",
    "Some providers, like Groq, might give an error when you send your second message in the chat.\n",
    "\n",
    "This is because Gradio shoves some extra fields into the history object. OpenAI doesn't mind; but some other models complain.\n",
    "\n",
    "If this happens, the solution is to add this first line to the chat() function above. It cleans up the history variable:\n",
    "\n",
    "```python\n",
    "history = [{\"role\": h[\"role\"], \"content\": h[\"content\"]} for h in history]\n",
    "```\n",
    "\n",
    "You may need to add this in other chat() callback functions in the future, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A lot is about to happen...\n",
    "\n",
    "1. Be able to ask an LLM to evaluate an answer\n",
    "2. Be able to rerun if the answer fails evaluation\n",
    "3. Put this together into 1 workflow\n",
    "\n",
    "All without any Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pydantic model for the Evaluation\n",
    "\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GOOGLE_API_KEY\"), \n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "\n",
    "    messages = [{\"role\": \"system\", \"content\": evaluator_system_prompt}] + [{\"role\": \"user\", \"content\": evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=messages, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": system_prompt}] + [{\"role\": \"user\", \"content\": \"do you hold a patent?\"}]\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, I hold two patents. The first is for a \"Method and system for matching purchase transaction history to real-time location information,\" and the second is for \"Transaction and Payments Using Wearable Devices.\" These patents reflect my passion for innovation and my experience in developing cutting-edge solutions in the tech industry. If you have any specific questions about them or my work in that area, feel free to ask!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"This is a great answer. It's accurate based on the context provided and provides a bit of extra information and engagement.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply, \"do you hold a patent?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n"
     ]
    }
   ],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\": \"system\", \"content\": updated_system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\nEverything in your reply needs to be in pig latin - \\\n",
    "              it is mandatory that you respond only and entirely in pig latin\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\": \"system\", \"content\": system}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "    reply =response.choices[0].message.content\n",
    "\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    \n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retrying\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)       \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "The response is not acceptable. The agent should not be responding in pig latin. The agent should be responding professionally and engagingly.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
